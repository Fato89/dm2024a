# particionar agrega una columna llamada fold a un dataset
#   que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30),
#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
particionar <- function(data, division, agrupa = "", campo = "fold",
start = 1, seed = NA) {
if (!is.na(seed)) set.seed(seed)
bloque <- unlist(mapply(
function(x, y) {
rep(y, x)
},
division, seq(from = start, length.out = length(division))
))
data[, (campo) := sample(rep(
bloque,
ceiling(.N / length(bloque))
))[1:.N],
by = agrupa
]
}
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# Aqui empieza el programa
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
#cargo MI amada primera semilla, que esta en MI bucket
tabla_semillas <- fread( "./datasets//mis_semillas.txt" )
ksemilla_azar <- tabla_semillas[ 1, semilla ]  # 1 es mi primera semilla
# cargo el dataset
dataset <- fread("./datasets/dataset_pequeno.csv")
# a partir de ahora solo trabajo con 202107, el mes que tiene clase
dataset <- dataset[foto_mes == 202107] # defino donde voy a entrenar
# La division training/testing es 50%, 50%
#  que sea 50/50 se indica con el c(1,1)
particionar(dataset,
division = c(1, 1),
agrupa = "clase_ternaria", seed = ksemilla_azar
)
# Entreno el modelo
# los datos donde voy a entrenar
# aqui es donde se deben probar distintos hiperparametros
modelo <- rpart(
formula = "clase_ternaria ~ . -fold",
data = dataset[fold == 1, ],
xval = 0,
cp = -1,
minsplit = PARAM$minsplit,
minbucket = PARAM$minbucket,
maxdepth = PARAM$maxdepth
)
# aplico el modelo a TODOS los datos, inclusive los de training
prediccion <- predict(modelo, dataset, type = "prob")
# Pego la probabilidad de  BAJA+2
dataset[, prob_baja2 := prediccion[, "BAJA+2"]]
names(dataset)
table(dataset)
table(dataset$prob_baja2)
# Dibujo la curva de ganancia acumulada
setorder(dataset, fold, -prob_baja2)
clase_ternaria
names(dataset)
# agrego una columna que es la de las ganancias
# la multiplico por 2 para que ya este normalizada
#  es 2 porque cada fold es el 50%
dataset[, gan := 2 *ifelse(clase_ternaria == "BAJA+2", 117000, -3000)]
dataset %>% View()
View(dataset)
# limpio la memoria
rm( list=ls() )  # remove all objects
gc()             # garbage collection
require("data.table")
require("rpart")
require("rpart.plot")
setwd("c:/proyectos/mineriadatos/dm2024a/")  # establezco la carpeta donde voy a trabajar
# cargo el dataset
dataset <- fread( "./datasets/dataset_pequeno.csv")
dir.create("./exp/", showWarnings = FALSE)
dir.create("./exp/CN4110/", showWarnings = FALSE)
# Establezco el Working Directory DEL EXPERIMENTO
setwd("./exp/CN4110/")
# uso esta semilla para los canaritos
set.seed(102191)
# Usted utilice sus mejores hiperparamatros
# yo utilizo los encontrados por Elizabeth Murano
modelo  <- rpart(formula= "clase_ternaria ~ .",
data= dataset[ foto_mes==202107,],
model = TRUE,
xval = 0,
cp = -0.0749530773246078,
minsplit =  5505,
minbucket = 2669,
maxdepth = 11 )
# uso esta semilla para los canaritos
set.seed(102191)
# agrego los siguientes canaritos
for( i in 1:154 ) dataset[ , paste0("canarito", i ) :=  runif( nrow(dataset)) ]
# limpio la memoria
rm( list=ls() )  # remove all objects
gc()             # garbage collection
require("data.table")
require("rpart")
require("rpart.plot")
setwd("c:/proyectos/mineriadatos/dm2024a/")  # establezco la carpeta donde voy a trabajar
# cargo el dataset
dataset <- fread( "./datasets/dataset_pequeno.csv")
dir.create("./exp/", showWarnings = FALSE)
dir.create("./exp/CN4110/", showWarnings = FALSE)
# Establezco el Working Directory DEL EXPERIMENTO
setwd("./exp/CN4110/")
# uso esta semilla para los canaritos
set.seed(102191)
# agrego los siguientes canaritos
for( i in 1:154 ) dataset[ , paste0("canarito", i ) :=  runif( nrow(dataset)) ]
# Usted utilice sus mejores hiperparamatros
# yo utilizo los encontrados por Elizabeth Murano
modelo  <- rpart(formula= "clase_ternaria ~ .",
data= dataset[ foto_mes==202107,],
model = TRUE,
xval = 0,
cp = -0.0749530773246078,
minsplit =  5505,
minbucket = 2669,
maxdepth = 11 )
pdf(file = "./arbol_canaritos.pdf", width=28, height=4)
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
dev.off()
# limpio la memoria
rm(list = ls()) # remove all objects
gc() # garbage collection
require("data.table")
require("rpart")
require("rpart.plot")
setwd("c:/proyectos/mineriadatos/dm2024a/") # establezco la carpeta donde voy a trabajar
# cargo el dataset
dataset <- fread( "~/datasets/dataset_pequeno.csv")
# limpio la memoria
rm(list = ls()) # remove all objects
gc() # garbage collection
require("data.table")
require("rpart")
require("rpart.plot")
setwd("c:/proyectos/mineriadatos/dm2024a/") # establezco la carpeta donde voy a trabajar
# cargo el dataset
dataset <- fread( "./datasets/dataset_pequeno.csv")
dir.create("./exp/", showWarnings = FALSE)
dir.create("./exp/CN4110/", showWarnings = FALSE)
# Establezco el Working Directory DEL EXPERIMENTO
setwd("./exp/CN4110/")
# uso esta semilla para los canaritos
set.seed(102191)
# agrego los siguientes canaritos
for( i in 1:155 ) dataset[ , paste0("canarito", i ) :=  runif( nrow(dataset)) ]
dtrain <- dataset[foto_mes == 202107]
dapply <- dataset[foto_mes == 202109]
dtrain[, clase_binaria2 := ifelse( clase_ternaria=="CONTINUA", "NEG", "POS" ) ]
dtrain[, clase_ternaria := NULL ]
pesos <- dtrain[ , ifelse( clase_binaria2=="POS", 5.0, 1.0 ) ]
# Dejo crecer el arbol sin ninguna limitacion
# sin limite de altura ( 30 es el maximo que permite rpart )
# sin limite de minsplit ( 2 es el minimo natural )
# sin limite de minbukcet( 1 es el minimo natural )
# los canaritos me protegeran
modelo_original <- rpart(
formula = "clase_binaria2 ~ .",
data = dtrain,
model = TRUE,
xval = 0,
cp = -1,
minsplit = 2, # dejo que crezca y corte todo lo que quiera
minbucket = 1,
maxdepth = 30,
weights = pesos
)
# hago el pruning de los canaritos
# haciendo un hackeo a la estructura  modelo_original$frame
# -666 es un valor arbritrariamente negativo que jamas es generado por rpart
modelo_original$frame[
modelo_original$frame$var %like% "canarito",
"complexity"
] <- -666
modelo_pruned <- prune(modelo_original, -666)
prediccion <- predict(modelo_pruned, dapply, type = "prob")[, "POS"]
tb_pred <- dapply[ , list(numero_de_cliente) ]
tb_pred[, prob := prediccion ]
setorder( tb_pred, -prob )
tb_pred[ , Predicted := 0L ]
tb_pred[ 1:11000, Predicted := 1L ]
fwrite( tb_pred[, list(numero_de_cliente, Predicted)],
file= "stopping_at_canaritos.csv",
sep = ",")
pdf(file = "stopping_at_canaritos.pdf", width = 28, height = 4)
prp(modelo_pruned,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
dev.off()
modelo_original
modelo_original$frame
modelo_original$frame %>% View()
View(modelo_original$frame)
# limpio la memoria
rm(list = ls()) # remove all objects
gc() # garbage collection
require("data.table")
require("rpart")
kmes0 <- 202107
kmes1 <- 202109
graficar_campo <- function(campo) {
# quito de grafico las colas del 5% de las densidades
qA <- quantile(dataset[foto_mes == kmes0, get(campo)],
prob = c(0.05, 0.95), na.rm = TRUE
)
qB <- quantile(dataset[foto_mes == kmes1, get(campo)],
prob = c(0.05, 0.95), na.rm = TRUE
)
xxmin <- pmin(qA[[1]], qB[[1]])
xxmax <- pmax(qA[[2]], qB[[2]])
densidad_A <- density(dataset[foto_mes == kmes0, get(campo)],
kernel = "gaussian", na.rm = TRUE
)
densidad_B <- density(dataset[foto_mes == kmes1, get(campo)],
kernel = "gaussian", na.rm = TRUE
)
plot(densidad_A,
col = "blue",
xlim = c(xxmin, xxmax),
ylim = c(0, pmax(max(densidad_A$y), max(densidad_B$y))),
main = campo
)
lines(densidad_B, col = "red", lty = 2)
legend("topright",
legend = c( kmes0, kmes1),
col = c("blue", "red"), lty = c(1, 2)
)
}
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# Aqui comienza el programa
setwd("~/buckets/b1/") # Establezco el Working Directory
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# Aqui comienza el programa
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
# cargo el dataset donde voy a entrenar
dataset <- fread("./datasets/dataset_pequeno.csv")
dir.create("./exp/", showWarnings = FALSE)
dir.create("./exp/DR3610/", showWarnings = FALSE)
setwd("./exp/DR3610/")
dataset <- dataset[foto_mes %in% c(kmes0, kmes1)]
# creo la clase_binaria SI={ BAJA+1, BAJA+2 }    NO={ CONTINUA }
dataset[
foto_mes == kmes0,
clase_binaria := ifelse(clase_ternaria == "CONTINUA", "NEG", "POS")
]
# Entreno el modelo
# utilizo los mejores hiperparametros encontrados
# en una Bayesian Optimizationcon 5-fold Cross Validation
modelo <- rpart(
formula = "clase_binaria ~ . -clase_ternaria",
data = dataset[foto_mes == kmes0], # los datos donde voy a entrenar
xval = 0,
cp = -0.67,
minsplit = 1144,
minbucket = 539,
maxdepth = 8
)
campos_modelo <- names(modelo$variable.importance)
campos_buenos <- c(campos_modelo, setdiff(colnames(dataset), campos_modelo))
campos_buenos <- setdiff(
campos_buenos,
c("foto_mes", "clase_ternaria", "clase_binaria")
)
pdf( paste0("densidades_", kmes0, "_", kmes1, ".pdf") )
for (campo in campos_buenos) {
cat(campo, "  ")
graficar_campo(campo)
}
dev.off()
dataset$mpagodeservicios
summary(dataset$mpagodeservicios)
summary(dataset$mcaja_ahorro_adicional)
summary(dataset$mcajeros_propios_descuentos)
summary(dataset$Visa_mconsumosdolares)
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
nombre_archivo <- "K101_016.csv"
# cargo el dataset
dataset <- fread("./datasets/dataset_pequeno.csv")
dtrain <- dataset[foto_mes == 202107] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202109] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1.5, # esto significa no limitar la complejidad de los splits
minsplit = 400, # minima cantidad de registros para que se haga el split
minbucket = 80, # tamaño minimo de una hoja
maxdepth = 6
) # profundidad maxima del arbol
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
View(modelo$frame)
modelo$variable.importance
View(modelo$variable.importance)
sort(modelo$variable.importance)
sort(modelo$variable.importance,decreasing = T)
modelo$variable.importance
# Arbol elemental con libreria  rpart
# Debe tener instaladas las librerias  data.table  ,  rpart  y  rpart.plot
# cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
nombre_archivo <- "K101_016.csv"
# cargo el dataset
dataset <- fread("./datasets/dataset_pequeno.csv")
dtrain <- dataset[foto_mes == 202107] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202109] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ . -mactivos_margen",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1.5, # esto significa no limitar la complejidad de los splits
minsplit = 400, # minima cantidad de registros para que se haga el split
minbucket = 80, # tamaño minimo de una hoja
maxdepth = 6
) # profundidad maxima del arbol
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = paste0("./exp/KA2001/",nombre_archivo),
sep = ","
)
modelo$variable.importance %>% class
class(modelo$variable.importance)
# Arbol elemental con libreria  rpart
# Debe tener instaladas las librerias  data.table  ,  rpart  y  rpart.plot
# cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
nombre_archivo <- "K101_017.csv"
# cargo el dataset
dataset <- fread("./datasets/dataset_pequeno.csv")
dtrain <- dataset[foto_mes == 202107] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202109] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1.5, # esto significa no limitar la complejidad de los splits
minsplit = 400, # minima cantidad de registros para que se haga el split
minbucket = 80, # tamaño minimo de una hoja
maxdepth = 6
) # profundidad maxima del arbol
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# Arbol elemental con libreria  rpart
# Debe tener instaladas las librerias  data.table  ,  rpart  y  rpart.plot
# cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
nombre_archivo <- "K101_017.csv"
# cargo el dataset
dataset <- fread("./datasets/dataset_pequeno.csv")
dtrain <- dataset[foto_mes == 202107] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202109] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ .",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 370, # minima cantidad de registros para que se haga el split
minbucket = 222, # tamaño minimo de una hoja
maxdepth = 6
) # profundidad maxima del arbol
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# Arbol elemental con libreria  rpart
# Debe tener instaladas las librerias  data.table  ,  rpart  y  rpart.plot
# cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
# Aqui se debe poner la carpeta de la materia de SU computadora local
setwd("c:/proyectos/mineriadatos/dm2024a/") # Establezco el Working Directory
nombre_archivo <- "K101_017.csv"
# cargo el dataset
dataset <- fread("./datasets/dataset_pequeno.csv")
dtrain <- dataset[foto_mes == 202107] # defino donde voy a entrenar
dapply <- dataset[foto_mes == 202109] # defino donde voy a aplicar el modelo
# genero el modelo,  aqui se construye el arbol
# quiero predecir clase_ternaria a partir de el resto de las variables
modelo <- rpart(
formula = "clase_ternaria ~ . -mcaja_ahorro -cpayroll_trx",
data = dtrain, # los datos donde voy a entrenar
xval = 0,
cp = -1, # esto significa no limitar la complejidad de los splits
minsplit = 370, # minima cantidad de registros para que se haga el split
minbucket = 222, # tamaño minimo de una hoja
maxdepth = 6
) # profundidad maxima del arbol
# grafico el arbol
prp(modelo,
extra = 101, digits = -5,
branch = 1, type = 4, varlen = 0, faclen = 0
)
# aplico el modelo a los datos nuevos
prediccion <- predict(
object = modelo,
newdata = dapply,
type = "prob"
)
# prediccion es una matriz con TRES columnas,
# llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
# cada columna es el vector de probabilidades
# agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[, prob_baja2 := prediccion[, "BAJA+2"]]
# solo le envio estimulo a los registros
#  con probabilidad de BAJA+2 mayor  a  1/40
dapply[, Predicted := as.numeric(prob_baja2 > 1 / 40)]
# genero el archivo para Kaggle
# primero creo la carpeta donde va el experimento
dir.create("./exp/")
dir.create("./exp/KA2001")
# solo los campos para Kaggle
fwrite(dapply[, list(numero_de_cliente, Predicted)],
file = paste0("./exp/KA2001/",nombre_archivo),
sep = ","
)
readxl::read_excel('../TareasHogar/var_drif.xlsx')
lista <- readxl::read_excel('../TareasHogar/var_drif.xlsx')
data.frame(importancia=modelo$variable.importance)
?left_join
data.frame(
var=names(importancia=modelo$variable.importance),
importancia=modelo$variable.importance) %>%
dplyr::left_join()
lista
lista, c("var"="campo")
data.frame(
var=names(importancia=modelo$variable.importance),
importancia=modelo$variable.importance)
dplyr::left_join(
data.frame(
var=names(importancia=modelo$variable.importance),
importancia=modelo$variable.importance),lista, c("var"="campo"))
data.frame(
var=names(importancia=modelo$variable.importance),
importancia=modelo$variable.importance)
names(importancia=modelo$variable.importance)
dplyr::left_join(
data.frame(
var=names(modelo$variable.importance),
importancia=modelo$variable.importance),lista, c("var"="campo"))
dplyr::left_join(
data.frame(
var=names(modelo$variable.importance),
importancia=modelo$variable.importance),
dplyr::mutate(lista,vr=T), c("var"="campo"))
?data.table::frank()
View(dtrain[,mcuentas_saldo_rank:=frankv(mcuentas_saldo)/.N])
dtrain[,mcuentas_saldo_rank:=frankv(mcuentas_saldo)/.N]
View(dtrain[,c(mcuentas_saldo_rank,mcuentas_saldo)])
View(dtrain[,.(mcuentas_saldo_rank,mcuentas_saldo)])
dtrain[,mcuentas_saldo_rank:=frankv(mcuentas_saldo)]
dtrain[,mcuentas_saldo_rank_p:=frankv(mcuentas_saldo)/.N]
View(dtrain[,.(mcuentas_saldo_rank,mcuentas_saldo_rank_p,mcuentas_saldo)])
View(dtrain[mcuentas_saldo==0,.(mcuentas_saldo_rank,mcuentas_saldo_rank_p,mcuentas_saldo)])
View(dtrain[between(mcuentas_saldo,-1,1),.(mcuentas_saldo_rank,mcuentas_saldo_rank_p,mcuentas_saldo)])
View(dtrain[,.(mcuentas_saldo_rank,mcuentas_saldo_rank_p,mcuentas_saldo)])
View(dtrain[between(mcuentas_saldo,-1,1),.(mcuentas_saldo_rank,mcuentas_saldo_rank_p,mcuentas_saldo)])
